import asyncio
import websockets
import numpy as np
from faster_whisper import WhisperModel

SAMPLE_RATE = 16000
BUFFER_SECONDS = 1.5   # ğŸ”¥ ì‘ì„ìˆ˜ë¡ ì‹¤ì‹œê°„
BUFFER_SIZE = int(SAMPLE_RATE * BUFFER_SECONDS)

# CPU ìµœì í™” ëª¨ë¸
model = WhisperModel(
    "base",
    device="cpu",
    compute_type="int8"   # â­ í•µì‹¬ (ì†ë„ ëŒ€í­ â†‘)
)

audio_buffer = np.empty(0, dtype=np.float32)

async def handler(ws):
    global audio_buffer
    print("Client connected")

    async for message in ws:
        if not isinstance(message, bytes):
            continue

        chunk = np.frombuffer(message, dtype=np.float32)
        audio_buffer = np.concatenate([audio_buffer, chunk])

        if len(audio_buffer) < BUFFER_SIZE:
            continue

        audio = audio_buffer[:BUFFER_SIZE]
        audio_buffer = audio_buffer[BUFFER_SIZE:]

        # ğŸ”¥ faster-whisperëŠ” ë°”ë¡œ numpy ì…ë ¥ ê°€ëŠ¥
        segments, info = model.transcribe(
            audio,
            language=None,        # ìë™ ì–¸ì–´ ê°ì§€
            vad_filter=True,      # ë¬´ìŒ ì œê±°
            beam_size=1           # ì‹¤ì‹œê°„ìš©
        )

        text = ""
        for seg in segments:
            text += seg.text

        text = text.strip()
        if text:
            await ws.send(text)

async def main():
    async with websockets.serve(
        handler,
        "0.0.0.0",
        3000,
        max_size=None
    ):
        print("ğŸš€ Faster-Whisper STT Server started :3000")
        await asyncio.Future()

asyncio.run(main())
